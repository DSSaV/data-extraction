{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA-EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_yfinnace(stock, startDate, endDate, interval='1d'):\n",
    "    print(stock)\n",
    "    df = yf.download(stock, start=startDate, end=endDate, interval=interval, group_by='tickers')\n",
    "    df = df.drop(columns=['Adj Close'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(df, timeframe=-1):\n",
    "    df['Label'] = df[\"Close\"].shift(timeframe)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(percentage, df, dropLabels):\n",
    "    splitValue = int(len(df) * percentage) # Used for calculating the split for test train based on data size\n",
    "    \n",
    "    x = np.array(df.drop(dropLabels, 1)) # Drop all unused columns\n",
    "    y = np.ravel(df.Label) # take only labels\n",
    "\n",
    "    x_train, x_test = x[:splitValue], x[splitValue:]\n",
    "    y_train, y_test = y[:splitValue], y[splitValue:]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MM_Scaler(x_train, x_test):\n",
    "\n",
    "    linearScaler = MinMaxScaler().fit(x_train)\n",
    "\n",
    "    # Scale train and test\n",
    "    x_train = linearScaler.transform(x_train)\n",
    "    x_test = linearScaler.transform(x_test)\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization():\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(x_train, x_test):\n",
    "    scaler = StandardScaler().fit(x_train)\n",
    "    \n",
    "    # Scale train and test\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA FEATURES\n",
    "\n",
    "Data features are based on this study: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4873195/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TYPE 1 FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic %K\n",
    "def stochastic_k(df, timeframe=14):\n",
    "    return df.join(pd.Series(100 * ((df['Close'] - df['Low'].rolling(timeframe).min()) / (df['High'].rolling(timeframe).max() - df['Low'].rolling(timeframe).min())), name='stocK'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic %D\n",
    "def stochastic_d(df, timeframe=3):\n",
    "    return df.join(pd.Series(df['stocK'].rolling(timeframe).mean(), name='stocD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic slow %D\n",
    "def stochastic_sd(df, timeframe=3):\n",
    "    return df.join(pd.Series(df['stocD'].rolling(timeframe).mean(), name='stocSD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(df, timeframe=14):\n",
    "    return df.join(pd.Series(df['Close'].diff(timeframe), name='Momentum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Rate of change\n",
    "def rate_of_change(df, timeframe):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Larry William's %R\n",
    "def larry_williams(df, timeframe):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# A/O Oscillator (accumulation/distribution oscillator)\n",
    "def ao_oscillator(df, timeframe):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Disparity\n",
    "def disparity(df, timeframe):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Price oscillator\n",
    "def price_oscillator(df, timeframe):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Commodity channel index\n",
    "def commodity_channel_index(df, timeframe):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Relative strength index\n",
    "def relative_strength_index(df, timeframe):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature addition function\n",
    "def add_type1_features(df, timeframe):\n",
    "    df = stochastic_k(df, timeframe)\n",
    "    df = stochastic_d(df)  #Default as 3 \n",
    "    df = stochastic_sd(df) #Default as 3 \n",
    "    df = momentum(df, timeframe)\n",
    "    # Rate of Change\n",
    "    # Larry William's %R\n",
    "    # A/O Oscillator\n",
    "    # Disparity in 5 d\n",
    "    # Disparity in 10 days\n",
    "    # Price oscillator\n",
    "    # CCI\n",
    "    # RSI\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TYPE 2 FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# OBV\n",
    "def obv(df, timeframe):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Average\n",
    "def moving_average(df, timeframe):\n",
    "    return df.join(pd.Series(df[\"Close\"].rolling(timeframe).sum()/timeframe, name='MA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#BIAS6\n",
    "def bias():\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# PSY\n",
    "def psy(df, timeframe):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SY\n",
    "def sy(df):\n",
    "    return df.join(pd.Series((np.log(df['Close']) - np.log(df['Close'].shift(1))) * 100 , name='SY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASY\n",
    "def asy(df, timeframe):\n",
    "    return df.join(pd.Series(df[\"SY\"].rolling(timeframe).sum()/timeframe, name='ASY' + str(timeframe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Feature addition function\n",
    "def add_type2_features(df, timeframe):\n",
    "    # OBV\n",
    "    df = moving_average(df, 5)\n",
    "    # BIAS6\n",
    "    # PSY\n",
    "    df = sy(df)\n",
    "    df = asy(df, 5)\n",
    "    df = asy(df, 4)\n",
    "    df = asy(df, 3)\n",
    "    df = asy(df, 2)\n",
    "    df = asy(df, 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data = fetch_yfinnace('NVDA', startDate='2019-01-08', endDate='2020-01-08', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>138.500000</td>\n",
       "      <td>144.889999</td>\n",
       "      <td>136.429993</td>\n",
       "      <td>143.399994</td>\n",
       "      <td>17729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>146.690002</td>\n",
       "      <td>146.779999</td>\n",
       "      <td>136.899994</td>\n",
       "      <td>139.830002</td>\n",
       "      <td>19650400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09</th>\n",
       "      <td>141.899994</td>\n",
       "      <td>144.490005</td>\n",
       "      <td>139.860001</td>\n",
       "      <td>142.580002</td>\n",
       "      <td>15431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-10</th>\n",
       "      <td>141.800003</td>\n",
       "      <td>145.580002</td>\n",
       "      <td>139.360001</td>\n",
       "      <td>145.229996</td>\n",
       "      <td>13078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11</th>\n",
       "      <td>144.330002</td>\n",
       "      <td>149.750000</td>\n",
       "      <td>143.210007</td>\n",
       "      <td>148.830002</td>\n",
       "      <td>21869100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close    Volume\n",
       "Date                                                                \n",
       "2019-01-07  138.500000  144.889999  136.429993  143.399994  17729000\n",
       "2019-01-08  146.690002  146.779999  136.899994  139.830002  19650400\n",
       "2019-01-09  141.899994  144.490005  139.860001  142.580002  15431500\n",
       "2019-01-10  141.800003  145.580002  139.360001  145.229996  13078900\n",
       "2019-01-11  144.330002  149.750000  143.210007  148.830002  21869100"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 5)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On average there are ~ 251 trading days per year, however, it might vary a little depending on the year.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: ADD LABEL AND FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_label(data)\n",
    "data = add_type1_features(data, 14)\n",
    "data = add_type2_features(data, 14)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Label</th>\n",
       "      <th>stocK</th>\n",
       "      <th>stocD</th>\n",
       "      <th>stocSD</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>MA</th>\n",
       "      <th>SY</th>\n",
       "      <th>ASY5</th>\n",
       "      <th>ASY4</th>\n",
       "      <th>ASY3</th>\n",
       "      <th>ASY2</th>\n",
       "      <th>ASY1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-31</th>\n",
       "      <td>137.259995</td>\n",
       "      <td>145.190002</td>\n",
       "      <td>136.380005</td>\n",
       "      <td>143.750000</td>\n",
       "      <td>21071300</td>\n",
       "      <td>144.729996</td>\n",
       "      <td>42.670676</td>\n",
       "      <td>22.021422</td>\n",
       "      <td>26.155683</td>\n",
       "      <td>-1.479996</td>\n",
       "      <td>142.179999</td>\n",
       "      <td>4.525209</td>\n",
       "      <td>-1.870123</td>\n",
       "      <td>-2.700879</td>\n",
       "      <td>1.358319</td>\n",
       "      <td>4.415431</td>\n",
       "      <td>4.525209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>144.500000</td>\n",
       "      <td>146.789993</td>\n",
       "      <td>142.580002</td>\n",
       "      <td>144.729996</td>\n",
       "      <td>15626200</td>\n",
       "      <td>149.179993</td>\n",
       "      <td>45.950447</td>\n",
       "      <td>36.668886</td>\n",
       "      <td>24.769444</td>\n",
       "      <td>-4.100006</td>\n",
       "      <td>139.095999</td>\n",
       "      <td>0.679423</td>\n",
       "      <td>-2.024819</td>\n",
       "      <td>1.188595</td>\n",
       "      <td>3.170095</td>\n",
       "      <td>2.602316</td>\n",
       "      <td>0.679423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-04</th>\n",
       "      <td>145.369995</td>\n",
       "      <td>150.679993</td>\n",
       "      <td>144.479996</td>\n",
       "      <td>149.179993</td>\n",
       "      <td>13214800</td>\n",
       "      <td>149.949997</td>\n",
       "      <td>60.843339</td>\n",
       "      <td>49.821487</td>\n",
       "      <td>36.170598</td>\n",
       "      <td>-1.260010</td>\n",
       "      <td>141.329999</td>\n",
       "      <td>3.028367</td>\n",
       "      <td>1.556549</td>\n",
       "      <td>3.134663</td>\n",
       "      <td>2.744333</td>\n",
       "      <td>1.853895</td>\n",
       "      <td>3.028367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-05</th>\n",
       "      <td>149.660004</td>\n",
       "      <td>151.429993</td>\n",
       "      <td>148.300003</td>\n",
       "      <td>149.949997</td>\n",
       "      <td>13560600</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>63.420327</td>\n",
       "      <td>56.738038</td>\n",
       "      <td>47.742804</td>\n",
       "      <td>0.080002</td>\n",
       "      <td>144.999997</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>2.610696</td>\n",
       "      <td>2.186957</td>\n",
       "      <td>1.407540</td>\n",
       "      <td>1.771599</td>\n",
       "      <td>0.514830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-06</th>\n",
       "      <td>151.289993</td>\n",
       "      <td>155.600006</td>\n",
       "      <td>151.070007</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>17561600</td>\n",
       "      <td>147.419998</td>\n",
       "      <td>73.627833</td>\n",
       "      <td>65.963833</td>\n",
       "      <td>57.507786</td>\n",
       "      <td>4.160004</td>\n",
       "      <td>148.121997</td>\n",
       "      <td>2.013604</td>\n",
       "      <td>2.152287</td>\n",
       "      <td>1.559056</td>\n",
       "      <td>1.852267</td>\n",
       "      <td>1.264217</td>\n",
       "      <td>2.013604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close    Volume  \\\n",
       "Date                                                                   \n",
       "2019-01-31  137.259995  145.190002  136.380005  143.750000  21071300   \n",
       "2019-02-01  144.500000  146.789993  142.580002  144.729996  15626200   \n",
       "2019-02-04  145.369995  150.679993  144.479996  149.179993  13214800   \n",
       "2019-02-05  149.660004  151.429993  148.300003  149.949997  13560600   \n",
       "2019-02-06  151.289993  155.600006  151.070007  153.000000  17561600   \n",
       "\n",
       "                 Label      stocK      stocD     stocSD  Momentum          MA  \\\n",
       "Date                                                                            \n",
       "2019-01-31  144.729996  42.670676  22.021422  26.155683 -1.479996  142.179999   \n",
       "2019-02-01  149.179993  45.950447  36.668886  24.769444 -4.100006  139.095999   \n",
       "2019-02-04  149.949997  60.843339  49.821487  36.170598 -1.260010  141.329999   \n",
       "2019-02-05  153.000000  63.420327  56.738038  47.742804  0.080002  144.999997   \n",
       "2019-02-06  147.419998  73.627833  65.963833  57.507786  4.160004  148.121997   \n",
       "\n",
       "                  SY      ASY5      ASY4      ASY3      ASY2      ASY1  \n",
       "Date                                                                    \n",
       "2019-01-31  4.525209 -1.870123 -2.700879  1.358319  4.415431  4.525209  \n",
       "2019-02-01  0.679423 -2.024819  1.188595  3.170095  2.602316  0.679423  \n",
       "2019-02-04  3.028367  1.556549  3.134663  2.744333  1.853895  3.028367  \n",
       "2019-02-05  0.514830  2.610696  2.186957  1.407540  1.771599  0.514830  \n",
       "2019-02-06  2.013604  2.152287  1.559056  1.852267  1.264217  2.013604  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: NORMALIZE AND SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(.8, data, ['Label', 'Open', 'High', 'Low' , 'Volume', 'stocK', 'stocD',\n",
    "                                                         'stocSD','Momentum', \"MA\", 'SY', \"ASY5\", \"ASY4\", \"ASY3\", \"ASY2\", \n",
    "                                                         \"ASY1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = MM_Scaler(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test = standardization(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.55489797] [2.26094034]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0], x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
